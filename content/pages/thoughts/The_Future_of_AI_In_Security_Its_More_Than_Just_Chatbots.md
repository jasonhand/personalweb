---
type: PostLayout
title: The Future of AI in Security – It’s More Than Just Chatbots Conferences
colors: colors-a
backgroundImage:
  type: BackgroundImage
  url: /images/bg2.jpg
  backgroundSize: cover
  backgroundPosition: center
  backgroundRepeat: no-repeat
  opacity: 75
date: '2025-01-30'
author: content/data/team/jason-hand.json
excerpt: >-
  I don’t think we’ve even begun to tap into AI’s full potential in security. Right now, it’s mostly acting as a force multiplier—helping humans do their jobs faster, not replacing them. AI tools are great for vulnerability management, generating security reports, and even reasoning through complex configurations.
featuredImage:
  type: ImageBlock
  url: /images/ai-devrel.jpg
  altText: Post thumbnail image
media:
  url: /images/ai-devrel.jpg
  altText: altText of the image
  caption: Caption of the image
  elementId: ''
  type: ImageBlock
bottomSections:
  - elementId: ''
    type: RecentPostsSection
    colors: colors-f
    variant: variant-d
    subtitle: Recent posts
    showDate: true
    showAuthor: false
    showExcerpt: true
    recentCount: 3
    styles:
      self:
        height: auto
        width: wide
        margin:
          - mt-0
          - mb-0
          - ml-0
          - mr-0
        padding:
          - pt-12
          - pb-56
          - pr-4
          - pl-4
        justifyContent: center
      title:
        textAlign: left
      subtitle:
        textAlign: left
      actions:
        justifyContent: center
    showFeaturedImage: true
    showReadMoreLink: true
---

Right now, most AI security tools are glorified chatbots—helpful, but not game-changing. That’s going to change. We’re moving toward AI that can take limited action on its own, with guardrails in place. Eventually, we’ll get to fully automated responses—but only if we have solid traceability and oversight.

But let’s not forget that attackers are using AI too. I picture a future where bots are fighting bots, and the winner is the one with the best dataset. AI is going to make phishing attacks more convincing, social engineering more sophisticated, and even allow bad actors to sneak into open-source projects with plausible-looking code contributions.

Security isn’t just about building better defenses—it’s about staying ahead of how AI is being used (and misused) on both sides.
