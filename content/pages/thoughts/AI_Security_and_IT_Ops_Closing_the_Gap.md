---
type: PostLayout
title: AI Security and IT Ops – Closing the Gap
colors: colors-a
backgroundImage:
  type: BackgroundImage
  url: /images/bg2.jpg
  backgroundSize: cover
  backgroundPosition: center
  backgroundRepeat: no-repeat
  opacity: 75
date: '2025-01-30'
author: content/data/team/jason-hand.json
excerpt: >-
  One thing I keep wondering: do security teams handle incidents the same way IT Ops does? I know some do, but I also know a lot of teams that don’t have a formal incident response process for security issues.
featuredImage:
  type: ImageBlock
  url: /images/ai-devrel.jpg
  altText: Post thumbnail image
media:
  url: /images/ai-devrel.jpg
  altText: altText of the image
  caption: Caption of the image
  elementId: ''
  type: ImageBlock
bottomSections:
  - elementId: ''
    type: RecentPostsSection
    colors: colors-f
    variant: variant-d
    subtitle: Recent posts
    showDate: true
    showAuthor: false
    showExcerpt: true
    recentCount: 3
    styles:
      self:
        height: auto
        width: wide
        margin:
          - mt-0
          - mb-0
          - ml-0
          - mr-0
        padding:
          - pt-12
          - pb-56
          - pr-4
          - pl-4
        justifyContent: center
      title:
        textAlign: left
      subtitle:
        textAlign: left
      actions:
        justifyContent: center
    showFeaturedImage: true
    showReadMoreLink: true
---

One thing I keep wondering: do security teams handle incidents the same way IT Ops does? I know some do, but I also know a lot of teams that don’t have a formal incident response process for security issues.

That’s where AI could help. If security incidents were treated more like infrastructure incidents—with ticketing, runbooks, and structured workflows—it’d be easier to integrate AI into the process. AI can surface relevant documents, automate some of the busywork, and help teams respond faster.

But here’s the catch: AI security is only as good as the data it has access to. Most AI tools today rely on the same few large models (ChatGPT, Claude, etc.), which means a lot of companies are depending on outside vendors for their AI security needs. That’s another external dependency to keep an eye on—because the last thing anyone on-call wants is a security tool that goes down when you need it most.
