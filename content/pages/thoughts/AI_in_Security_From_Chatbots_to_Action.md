---
type: PostLayout
title: AI in Security – From Chatbots to Action
colors: colors-a
backgroundImage:
  type: BackgroundImage
  url: /images/bg2.jpg
  backgroundSize: cover
  backgroundPosition: center
  backgroundRepeat: no-repeat
  opacity: 75
date: '2025-01-30'
author: content/data/team/jason-hand.json
excerpt: >-
  Most AI security tools today are just fancy chatbots that serve up information. That’s useful, but the real future is AI that can actually do things—fixing common issues, analyzing incidents, and even improving itself through feedback loops.
featuredImage:
  type: ImageBlock
  url: /images/ai-devrel.jpg
  altText: Post thumbnail image
media:
  url: /images/ai-devrel.jpg
  altText: altText of the image
  caption: Caption of the image
  elementId: ''
  type: ImageBlock
bottomSections:
  - elementId: ''
    type: RecentPostsSection
    colors: colors-f
    variant: variant-d
    subtitle: Recent posts
    showDate: true
    showAuthor: false
    showExcerpt: true
    recentCount: 3
    styles:
      self:
        height: auto
        width: wide
        margin:
          - mt-0
          - mb-0
          - ml-0
          - mr-0
        padding:
          - pt-12
          - pb-56
          - pr-4
          - pl-4
        justifyContent: center
      title:
        textAlign: left
      subtitle:
        textAlign: left
      actions:
        justifyContent: center
    showFeaturedImage: true
    showReadMoreLink: true
---

Most AI security tools today are just fancy chatbots that serve up information. That’s useful, but the real future is AI that can actually do things—fixing common issues, analyzing incidents, and even improving itself through feedback loops.

But security isn’t something you "solve." It’s an ongoing process. If you think you’ve got a perfect system, you’re already behind. AI-driven security tools need to be constantly tested, monitored, and adjusted.

AI is just another layer of the tech stack now, and we need to treat it like one. Just like we monitor networks and databases, we need to monitor what AI is doing—because unlike traditional systems, AI isn’t always predictable. And if we don’t understand how it’s making decisions, we’re setting ourselves up for failure.
